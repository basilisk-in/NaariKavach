{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50610ac1-6372-4307-a491-e787fc644695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from transformers import AutoFeatureExtractor, AutoModelForImageClassification\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34acb033-db89-49ba-8c86-d5894b805b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagni\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:30: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_id = \"locih/violence_classification\"\n",
    "# Load the model and feature extractor\n",
    "model_violence = ViTForImageClassification.from_pretrained(model_id)\n",
    "extractor_violence = ViTFeatureExtractor.from_pretrained(model_id)\n",
    "\n",
    "model_name = \"rizvandwiki/gender-classification-2\"\n",
    "extractor_gender = AutoFeatureExtractor.from_pretrained(model_name)\n",
    "model_gender = AutoModelForImageClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39b6198-a59b-4b7e-ae40-187cd2b418be",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_to_remove = \"op\"\n",
    "\n",
    "# Check if the directory exists before attempting to remove it\n",
    "if os.path.exists(directory_to_remove) and os.path.isdir(directory_to_remove):\n",
    "    try:\n",
    "        shutil.rmtree(directory_to_remove)\n",
    "        print(f\"Directory '{directory_to_remove}' and its contents removed successfully.\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error: {directory_to_remove} : {e.strerror}\")\n",
    "else:\n",
    "    print(f\"Directory '{directory_to_remove}' does not exist or is not a directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "253cb5e1-2abd-43e9-aaea-b23f582495a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"violent/cam1/28.mp4\" #37 violent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cd4363-9a48-4901-a534-c1f11b5026e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_and_save_frames(video_path, save_dir=\"op\", num_frames=15):\n",
    "    # Create the save directory if it doesn't exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    if total_frames == 0:\n",
    "        raise ValueError(\"❌ No frames found in the video. Check if the path is correct.\")\n",
    "\n",
    "    print(f\"🎞️ Total frames in video: {total_frames}\")\n",
    "\n",
    "    # Determine frame positions to capture\n",
    "    interval = total_frames // num_frames\n",
    "    frame_ids = [i * interval for i in range(num_frames)]\n",
    "\n",
    "    print(f\"📸 Capturing frames at positions: {frame_ids}\")\n",
    "\n",
    "    saved_count = 0\n",
    "    for i in range(total_frames):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if i in frame_ids:\n",
    "            filename = os.path.join(save_dir, f\"frame_{saved_count + 1}.jpg\")\n",
    "            cv2.imwrite(filename, frame)\n",
    "            print(f\"✅ Saved {filename}\")\n",
    "            saved_count += 1\n",
    "\n",
    "        if saved_count >= num_frames:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    print(f\" Done! {saved_count} frames saved to '{save_dir}'\")\n",
    "\n",
    "# === Example Usage ===\n",
    "save_dir = \"op\"\n",
    "extract_and_save_frames(video_path, save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "818811a4-77ae-488f-a4d7-47038c48c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gender(frames):\n",
    "    gen=[]\n",
    "    for path in frames.iterdir():\n",
    "        frame = cv2.imread(path)\n",
    "        image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        inputs = extractor_gender(images=image, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model_gender(**inputs)\n",
    "        \n",
    "        # Convert logits to predicted label\n",
    "        predicted_class = outputs.logits.argmax(-1).item()\n",
    "        label = model_gender.config.id2label[predicted_class]\n",
    "\n",
    "        gen.append(label)\n",
    "    return max(set(gen), key=gen.count)\n",
    "\n",
    "pt = pathlib.Path(\"op\")\n",
    "\n",
    "def violence_detection(frames):\n",
    "    l = []\n",
    "    for i in frames.iterdir():\n",
    "        image = Image.open(i)\n",
    "        \n",
    "        # Preprocess the image\n",
    "        inputs = extractor_violence(images=image, return_tensors=\"pt\")\n",
    "        \n",
    "        # Perform inference\n",
    "        with torch.no_grad():\n",
    "            outputs = model_violence(**inputs)\n",
    "            logits = outputs.logits\n",
    "            predicted_class_idx = logits.argmax(-1).item()\n",
    "        \n",
    "        # Print the predicted class\n",
    "        l.append(model_violence.config.id2label[predicted_class_idx])\n",
    "    f = max(set(l), key=l.count)\n",
    "    if f=='safe':\n",
    "        return 0,l\n",
    "    else:\n",
    "        return 1,l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7ab7e2-b1cb-40fd-9ce7-043d85d02410",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_gender(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd7a13a-c589-48a0-86e4-8c54c44704c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "o,l = violence_detection(pt)\n",
    "o,l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e884569-379c-4b53-b32b-995d0af9b6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sos():\n",
    "    url = \"http://localhost:8000/api/create-sos/\"\n",
    "\n",
    "# JSON payload\n",
    "    payload = {\n",
    "        \"name\": \"cam001\",\n",
    "        \"sos_type\": 1,\n",
    "        \"initial_latitude\": 22.554450,\n",
    "        \"initial_longitude\": 88.349850\n",
    "    }\n",
    "    \n",
    "    # Send POST request\n",
    "    response = requests.post(url, json=payload)\n",
    "    res = response.json()\n",
    "    # Print result\n",
    "    print(\"Status Code:\", response.status_code)\n",
    "    print(\"Response:\", response.json())\n",
    "    return res[\"sos_id\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def upload_images():\n",
    "    # API endpoint\n",
    "    url = \"http://localhost:8000/api/upload-sos-images/\"\n",
    "    \n",
    "    \n",
    "    # Form data\n",
    "    sos_id = create_sos()\n",
    "    descriptions = [\"Evidence photo\", \"Location photo\"]\n",
    "    image_dir = \"op\"\n",
    "    # Open image files\n",
    "    files = [\n",
    "    (\"images\", open(os.path.join(image_dir, filename), \"rb\"))\n",
    "    for filename in os.listdir(image_dir)\n",
    "    if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\"))  # Optional: filter by image type\n",
    "    ]\n",
    "    \n",
    "    # Add descriptions (same key, different values)\n",
    "    data = [(\"sos_id\", str(sos_id))]\n",
    "    data += [(\"descriptions\", desc) for desc in descriptions]\n",
    "    \n",
    "    # Send POST request\n",
    "    response = requests.post(url, files=files, data=data)\n",
    "    \n",
    "    # Print result\n",
    "    print(\"Status Code:\", response.status_code)\n",
    "    print(\"Response:\", response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7a8df2-e712-4875-8bcd-fd2ea6d028dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if o==1:\n",
    "    upload_images()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19ae9513-1137-40fa-97c3-54227f78f832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(video_path = \"violent/cam1/87.mp4\"):\n",
    "    directory_to_remove = \"op\"\n",
    "\n",
    "    # Check if the directory exists before attempting to remove it\n",
    "    if os.path.exists(directory_to_remove) and os.path.isdir(directory_to_remove):\n",
    "        try:\n",
    "            shutil.rmtree(directory_to_remove)\n",
    "            print(f\"Directory '{directory_to_remove}' and its contents removed successfully.\")\n",
    "        except OSError as e:\n",
    "            print(f\"Error: {directory_to_remove} : {e.strerror}\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory_to_remove}' does not exist or is not a directory.\")\n",
    "\n",
    "    extract_and_save_frames(video_path)\n",
    "    pt = pathlib.Path(\"op\")\n",
    "    gender = predict_gender(pt)\n",
    "\n",
    "    if gender=='female':\n",
    "        print('females detected, proceeding to violence detection')\n",
    "        o,l = violence_detection(pt)\n",
    "        print(l)\n",
    "\n",
    "        if o==1:\n",
    "            print(\"violence detected, sending frames to server\")\n",
    "            upload_images()\n",
    "    else:\n",
    "        print('females not detected, exiting')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "798b0aa6-7c1d-430a-b0ed-d7fb14188d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'op' and its contents removed successfully.\n",
      "🎞️ Total frames in video: 327\n",
      "📸 Capturing frames at positions: [0, 21, 42, 63, 84, 105, 126, 147, 168, 189, 210, 231, 252, 273, 294]\n",
      "✅ Saved op\\frame_1.jpg\n",
      "✅ Saved op\\frame_2.jpg\n",
      "✅ Saved op\\frame_3.jpg\n",
      "✅ Saved op\\frame_4.jpg\n",
      "✅ Saved op\\frame_5.jpg\n",
      "✅ Saved op\\frame_6.jpg\n",
      "✅ Saved op\\frame_7.jpg\n",
      "✅ Saved op\\frame_8.jpg\n",
      "✅ Saved op\\frame_9.jpg\n",
      "✅ Saved op\\frame_10.jpg\n",
      "✅ Saved op\\frame_11.jpg\n",
      "✅ Saved op\\frame_12.jpg\n",
      "✅ Saved op\\frame_13.jpg\n",
      "✅ Saved op\\frame_14.jpg\n",
      "✅ Saved op\\frame_15.jpg\n",
      " Done! 15 frames saved to 'op'\n",
      "females detected, proceeding to violence detection\n",
      "['unsafe', 'unsafe', 'unsafe', 'unsafe', 'unsafe', 'unsafe', 'unsafe', 'safe', 'unsafe', 'safe', 'safe', 'safe', 'safe', 'safe', 'unsafe']\n",
      "violence detected, sending frames to server\n",
      "Status Code: 201\n",
      "Response: {'status': 'success', 'message': 'SOS created successfully', 'sos_id': 6, 'room_id': '21d16333-928f-4a32-8a90-dfef1b9fb858'}\n",
      "Status Code: 201\n",
      "Response: {'status': 'success', 'message': 'Successfully uploaded 15 image(s)', 'uploaded_images': [{'id': 46, 'sos_request': 6, 'image': 'http://localhost:8000/media/sos_images/frame_1_rvJfhkV.jpg', 'image_url': 'http://localhost:8000/media/sos_images/frame_1_rvJfhkV.jpg', 'description': 'Evidence photo', 'uploaded_at': '2025-06-27T08:08:10.770009Z'}, {'id': 47, 'sos_request': 6, 'image': 'http://localhost:8000/media/sos_images/frame_10_crQbWci.jpg', 'image_url': 'http://localhost:8000/media/sos_images/frame_10_crQbWci.jpg', 'description': 'Location photo', 'uploaded_at': '2025-06-27T08:08:10.806308Z'}, {'id': 48, 'sos_request': 6, 'image': 'http://localhost:8000/media/sos_images/frame_11_C2XLJFN.jpg', 'image_url': 'http://localhost:8000/media/sos_images/frame_11_C2XLJFN.jpg', 'description': '', 'uploaded_at': '2025-06-27T08:08:10.836310Z'}, {'id': 49, 'sos_request': 6, 'image': 'http://localhost:8000/media/sos_images/frame_12_QXPYeFR.jpg', 'image_url': 'http://localhost:8000/media/sos_images/frame_12_QXPYeFR.jpg', 'description': '', 'uploaded_at': '2025-06-27T08:08:10.864778Z'}, {'id': 50, 'sos_request': 6, 'image': 'http://localhost:8000/media/sos_images/frame_13_eKX4oVL.jpg', 'image_url': 'http://localhost:8000/media/sos_images/frame_13_eKX4oVL.jpg', 'description': '', 'uploaded_at': '2025-06-27T08:08:10.890020Z'}, {'id': 51, 'sos_request': 6, 'image': 'http://localhost:8000/media/sos_images/frame_14_pyyKYvh.jpg', 'image_url': 'http://localhost:8000/media/sos_images/frame_14_pyyKYvh.jpg', 'description': '', 'uploaded_at': '2025-06-27T08:08:10.915014Z'}, {'id': 52, 'sos_request': 6, 'image': 'http://localhost:8000/media/sos_images/frame_15_4kOxHkL.jpg', 'image_url': 'http://localhost:8000/media/sos_images/frame_15_4kOxHkL.jpg', 'description': '', 'uploaded_at': '2025-06-27T08:08:10.948020Z'}, {'id': 53, 'sos_request': 6, 'image': 'http://localhost:8000/media/sos_images/frame_2_CrnCMwq.jpg', 'image_url': 'http://localhost:8000/media/sos_images/frame_2_CrnCMwq.jpg', 'description': '', 'uploaded_at': '2025-06-27T08:08:10.978027Z'}, {'id': 54, 'sos_request': 6, 'image': 'http://localhost:8000/media/sos_images/frame_3_LlLYIyz.jpg', 'image_url': 'http://localhost:8000/media/sos_images/frame_3_LlLYIyz.jpg', 'description': '', 'uploaded_at': '2025-06-27T08:08:11.010276Z'}, {'id': 55, 'sos_request': 6, 'image': 'http://localhost:8000/media/sos_images/frame_4_LOlctj3.jpg', 'image_url': 'http://localhost:8000/media/sos_images/frame_4_LOlctj3.jpg', 'description': '', 'uploaded_at': '2025-06-27T08:08:11.050274Z'}, {'id': 56, 'sos_request': 6, 'image': 'http://localhost:8000/media/sos_images/frame_5_qzFz3c8.jpg', 'image_url': 'http://localhost:8000/media/sos_images/frame_5_qzFz3c8.jpg', 'description': '', 'uploaded_at': '2025-06-27T08:08:11.080862Z'}, {'id': 57, 'sos_request': 6, 'image': 'http://localhost:8000/media/sos_images/frame_6_YtqWnWa.jpg', 'image_url': 'http://localhost:8000/media/sos_images/frame_6_YtqWnWa.jpg', 'description': '', 'uploaded_at': '2025-06-27T08:08:11.109951Z'}, {'id': 58, 'sos_request': 6, 'image': 'http://localhost:8000/media/sos_images/frame_7_cJiv2wE.jpg', 'image_url': 'http://localhost:8000/media/sos_images/frame_7_cJiv2wE.jpg', 'description': '', 'uploaded_at': '2025-06-27T08:08:11.140869Z'}, {'id': 59, 'sos_request': 6, 'image': 'http://localhost:8000/media/sos_images/frame_8_bOk5laD.jpg', 'image_url': 'http://localhost:8000/media/sos_images/frame_8_bOk5laD.jpg', 'description': '', 'uploaded_at': '2025-06-27T08:08:11.173888Z'}, {'id': 60, 'sos_request': 6, 'image': 'http://localhost:8000/media/sos_images/frame_9_b5KAMog.jpg', 'image_url': 'http://localhost:8000/media/sos_images/frame_9_b5KAMog.jpg', 'description': '', 'uploaded_at': '2025-06-27T08:08:11.201246Z'}]}\n"
     ]
    }
   ],
   "source": [
    "main(\"violent/cam1/87.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16905a8-4688-481d-8909-5c91d82eca3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
